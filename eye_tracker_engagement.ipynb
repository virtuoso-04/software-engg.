{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "163ac28550754cd58f78b0527eb2c06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_80b1a8572ea94097bac4ce57900a26ad",
            "width": ""
          }
        },
        "80b1a8572ea94097bac4ce57900a26ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-UE7bo8xzQ-",
        "outputId": "d97b21a7-2ad9-4a1b-a361-79d9e9ed99bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install dlib\n",
        "!apt-get install -y cmake\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing the dependencies"
      ],
      "metadata": {
        "id": "n4YTQxEvyOPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kx1YKzQyXBh",
        "outputId": "c2791777-bfdd-4298-80da-8e8236c4e3db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-09 20:37:52--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  39.0MB/s    in 1.6s    \n",
            "\n",
            "2025-01-09 20:37:54 (39.0 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML, Javascript\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import threading\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "\n",
        "# Common Functions\n",
        "def calculate_ear(eye):\n",
        "    \"\"\"Calculate the eye aspect ratio\"\"\"\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n",
        "\n",
        "def process_frame(frame, face_detector, landmark_predictor):\n",
        "    \"\"\"Process a single frame for eye tracking\"\"\"\n",
        "    if frame is None:\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_detector(gray)\n",
        "\n",
        "    for face in faces:\n",
        "        landmarks = landmark_predictor(gray, face)\n",
        "        landmarks_points = np.array([(p.x, p.y) for p in landmarks.parts()])\n",
        "\n",
        "        # Extract eye landmarks\n",
        "        left_eye = landmarks_points[36:42]\n",
        "        right_eye = landmarks_points[42:48]\n",
        "\n",
        "        # Draw eye contours\n",
        "        left_eye_hull = cv2.convexHull(left_eye)\n",
        "        right_eye_hull = cv2.convexHull(right_eye)\n",
        "        cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1)\n",
        "        cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
        "\n",
        "        # Calculate EAR\n",
        "        left_ear = calculate_ear(left_eye)\n",
        "        right_ear = calculate_ear(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "        # Determine engagement\n",
        "        gaze_direction = \"Engaged\" if avg_ear > 0.25 else \"Distracted\"\n",
        "\n",
        "        # Display metrics\n",
        "        cv2.putText(frame, f\"EAR: {avg_ear:.2f}\", (10, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "        cv2.putText(frame, f\"Status: {gaze_direction}\", (10, 60),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Method 1: Simple Frame-by-Frame Capture\n",
        "def js_to_image(js_reply):\n",
        "    \"\"\"Convert JS response to OpenCV image\"\"\"\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def video_stream():\n",
        "    js = Javascript('''\n",
        "    async function setupWebcam() {\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'none';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        return canvas.toDataURL('image/jpeg');\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "    return eval_js('setupWebcam()')\n",
        "\n",
        "def run_simple_tracking():\n",
        "    \"\"\"Run eye tracking with simple frame-by-frame capture\"\"\"\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "    landmark_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            js_reply = video_stream()\n",
        "            if js_reply:\n",
        "                frame = js_to_image(js_reply)\n",
        "                processed_frame = process_frame(frame, face_detector, landmark_predictor)\n",
        "                cv2_imshow(processed_frame)\n",
        "                output.clear()\n",
        "            time.sleep(1)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Stopped by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {str(e)}\")\n",
        "\n",
        "# Method 2: Continuous Display\n",
        "def get_video_stream():\n",
        "    \"\"\"Create continuous video stream display\"\"\"\n",
        "    js_code = \"\"\"\n",
        "    var video = document.createElement('video');\n",
        "    var div = document.createElement('div');\n",
        "    div.style.height = '400px';\n",
        "    video.style.height = '400px';\n",
        "    video.style.width = '600px';\n",
        "\n",
        "    document.querySelector(\"#output-area\").appendChild(div);\n",
        "    div.appendChild(video);\n",
        "\n",
        "    navigator.mediaDevices.getUserMedia({ video: true })\n",
        "        .then(function(stream) {\n",
        "            video.srcObject = stream;\n",
        "            video.play();\n",
        "        })\n",
        "        .catch(function(err) {\n",
        "            console.log(\"Error: \" + err);\n",
        "        });\n",
        "    \"\"\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "def run_continuous_tracking():\n",
        "    \"\"\"Run eye tracking with continuous display\"\"\"\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "    landmark_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "    output_image = widgets.Image()\n",
        "    display(output_image)\n",
        "\n",
        "    js_code = \"\"\"\n",
        "    async function captureFrame() {\n",
        "        const video = document.querySelector('video');\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        return canvas.toDataURL('image/jpeg');\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    def update_frame():\n",
        "        while True:\n",
        "            try:\n",
        "                frame_data = eval_js('captureFrame()')\n",
        "                if frame_data:\n",
        "                    frame_bytes = b64decode(frame_data.split(',')[1])\n",
        "                    frame_array = np.frombuffer(frame_bytes, dtype=np.uint8)\n",
        "                    frame = cv2.imdecode(frame_array, flags=1)\n",
        "\n",
        "                    processed_frame = process_frame(frame, face_detector, landmark_predictor)\n",
        "                    if processed_frame is not None:\n",
        "                        _, buffer = cv2.imencode('.jpg', processed_frame)\n",
        "                        output_image.value = buffer.tobytes()\n",
        "\n",
        "                time.sleep(0.1)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {str(e)}\")\n",
        "                break\n",
        "\n",
        "    get_video_stream()\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "    processing_thread = threading.Thread(target=update_frame)\n",
        "    processing_thread.daemon = True\n",
        "    processing_thread.start()\n",
        "\n",
        "# Choose which method to run\n",
        "def main(method='continuous'):\n",
        "    if method == 'simple':\n",
        "        run_simple_tracking()\n",
        "    else:\n",
        "        run_continuous_tracking()"
      ],
      "metadata": {
        "id": "ClpEslUv0ROE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For continuous display (recommended):\n",
        "main('continuous')\n",
        "\n",
        "# OR for simple frame-by-frame:\n",
        "main('simple')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "163ac28550754cd58f78b0527eb2c06e",
            "80b1a8572ea94097bac4ce57900a26ad"
          ]
        },
        "id": "VQhsPZrW0Vm1",
        "outputId": "055380c5-4097-45e8-bc14-302502fb1915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function setupWebcam() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        \n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        return canvas.toDataURL('image/jpeg');\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}